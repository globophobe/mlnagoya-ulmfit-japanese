<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="generator" content="Gatsby 2.13.67"/><title data-react-helmet="true">Fast.ai Lesson 4</title><link data-react-helmet="true" rel="stylesheet" href="https://fonts.googleapis.com/css?family=Muli"/><link as="script" rel="preload" href="/2-f8806a5584b02803e598.js"/><link as="script" rel="preload" href="/app-084c1664e71b26798f10.js"/><link as="script" rel="preload" href="/webpack-runtime-b22280da432b197f4c69.js"/><link as="fetch" rel="preload" href="/page-data/print/page-data.json" crossorigin="anonymous"/></head><body><script>(function() { try {
        var mode = localStorage.getItem('theme-ui-color-mode');
        if (!mode) return
        document.body.classList.add('theme-ui-' + mode);
      } catch (e) {} })();</script><noscript id="gatsby-noscript">This app works best with JavaScript enabled.</noscript><div id="___gatsby"><div style="outline:none" tabindex="-1" role="group" id="gatsby-focus-wrapper"><style data-emotion-css="13j5fvw">body{margin:0;}</style><style data-emotion-css="185eva7">.css-185eva7{width:100vw;height:100vh;font-size:1em;}@media screen and (min-width:40em){.css-185eva7{font-size:1em;}}@media screen and (min-width:52em){.css-185eva7{font-size:1em;}}@media screen and (min-width:64em){.css-185eva7{font-size:1em;}}.css-185eva7 *{box-sizing:border-box;}</style><div class="css-185eva7"><div style="outline:none;height:100%" tabindex="-1" role="group"><style data-emotion-css="znkm8c">.css-znkm8c{box-sizing:border-box;width:100%;height:100vh;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;overflow:hidden;position:relative;color:#000;background-color:#F5F5F5;font-family:Muli,monospace;font-size:20px;}@media screen and (min-width:40em){.css-znkm8c{font-size:24px;}}@media screen and (min-width:52em){.css-znkm8c{font-size:32px;}}@media screen and (min-width:64em){.css-znkm8c{font-size:48px;}}</style><div class="css-znkm8c"><style data-emotion-css="ixasx1">.css-ixasx1{font-family:inherit;line-height:1.125;font-weight:600;text-align:center;}</style><h1 class="css-ixasx1"><style data-emotion-css="13b0teh">.css-13b0teh{color:#26466D;}</style><a href="http://fast.ai" class="css-13b0teh">Fast.ai</a> Lesson 4</h1><h1 class="css-ixasx1">Natural Language Processing with ULMFiT</h1><h2 class="css-ixasx1">ULMFiTで自然言語処理</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">These slides are at Connpass. So you can check them out.</h1><h2 class="css-ixasx1">スライドはConnpassにアップされています。 是非みてください。</h2></div><div class="css-znkm8c"><style data-emotion-css="5r4te6">.css-5r4te6{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;text-align:center;}</style><div class="css-5r4te6"><style data-emotion-css="11ze7cv">.css-11ze7cv{width:50%;}</style><div class="css-11ze7cv"><h1 class="css-ixasx1">My username on Connpass is &quot;globophobe&quot;.</h1><h2 class="css-ixasx1">Connpassのユーザ名は「globophobe」です。</h2></div><div class="css-11ze7cv"><style data-emotion-css="wnzno2">.css-wnzno2{max-width:100%;height:auto;object-fit:cover;}</style><img src="/static/arex-76097303b9ffb50dd382495c83fb23b8.jpg" class="css-wnzno2"/></div></div></div><div class="css-znkm8c"><h1 class="css-ixasx1">A little while ago, I finished Fast.ai lesson four.</h1><h2 class="css-ixasx1">少し前、Fast.aiレッスン4を終えました。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">Coincidentally, Fast.ai has documentation to use <a href="https://course.fast.ai/start_azure.html" class="css-13b0teh">Microsoft Data Science Virtual Machines</a>.</h1><h2 class="css-ixasx1">偶然にも、Fast.aiにはMicrosoft Data Science Virtual Machinesを使用するためのドキュメントがあります。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">Azure Machine Learning seems useful.</h1><h2 class="css-ixasx1">Azure Machine Learningは役に立つだそうです。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">To continue, Fast.ai is a free deep learning Python library and curriculum.</h1><h2 class="css-ixasx1">それでは、Fast.aiの話を続けって、無料の機械学習Pythonライブラリとカリキュラムです。</h2></div><div class="css-znkm8c"><div class="css-5r4te6"><div class="css-11ze7cv"><h1 class="css-ixasx1">The teacher was Kaggle #1, and its president.</h1><h2 class="css-ixasx1">先生はKaggleの１位、そしてKaggleの組織の会長でした。</h2></div><div class="css-11ze7cv"><img src="/static/jeremy-howard-6be7fadb88986e2b2ddeef8a5c6f57b3.png" class="css-wnzno2"/></div></div></div><div class="css-znkm8c"><h1 class="css-ixasx1"><a href="https://course.fast.ai/videos/?lesson=1" class="css-13b0teh">Lesson 1</a> and <a href="https://course.fast.ai/videos/?lesson=2" class="css-13b0teh">lesson 2</a> explain how to create a CNN with ResNet for transfer learning.</h1><h2 class="css-ixasx1">レッスン1と2は、簡単に転送学習用のResNetを使用してCNNを作成方法を説明します。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1"><a href="https://course.fast.ai/videos/?lesson=3" class="css-13b0teh">Lesson 3</a> explains in more detail how to use Fast.ai for image processing.</h1><h2 class="css-ixasx1">レッスン3では、Fast.aiライブラリを使用して、画像処理をする方法についてさらに詳しく説明します。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1"><a href="https://course.fast.ai/videos/?lesson=4" class="css-13b0teh">Lesson 4</a> explains how to use Fast.ai for natural language processing (NLP).</h1><h2 class="css-ixasx1">レッスン4では、自然言語処理のために、Fasti.aiを利用する方法について説明します。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">Fast.ai uses transfer learning for NLP.</h1><h2 class="css-ixasx1">Fast.aiは自然言語処理のために転送学習を使用します</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">The paper &quot;<a href="https://arxiv.org/abs/1801.06146" class="css-13b0teh">Universal Language Model Fine-tuning for Text Classification</a>&quot; was published on arXiv.org in January 2018.</h1><h2 class="css-ixasx1">2018年1月にarXiv.orgで論文が公開されました。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">According to the paper, because the ULMFiT model doesn’t have to learn from scratch...</h1><h2 class="css-ixasx1">論文によると、ULMFiTモデルはゼロから学習することが必要ないので、</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">...it can generally reach higher accuracy with much less data and compute time.</h1><h2 class="css-ixasx1">一般に、少ないデータの量と計算時間で、より高い精度に達することが出来ます。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">ULMFit was state of the art (SOTA) for sentiment analysis on the Internet Movie Database (IMDB) until recently.</h1><h2 class="css-ixasx1">ULMFitは最近まで、IMDBデータセットで、感情分析の最先端でした。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">Presently, XLNet is number 1.</h1><h2 class="css-ixasx1">現在、XLNetは1位です。</h2><style data-emotion-css="k33856">.css-k33856{font-family:Muli,monospace;padding:16px;color:#26466D;background-color:#000;}</style><style data-emotion-css="110mgx6">.css-110mgx6{font-family:Muli,monospace;color:#26466D;}</style><pre class="css-110mgx6" style="display:block;overflow-x:auto;padding:0.5em;background:#F0F0F0;color:#444"><code>           XLNet            <span style="color:#880000">96.21</span>              
           ULMFiT           <span style="color:#880000">95.4</span>
</code></pre></div><div class="css-znkm8c"><h1 class="css-ixasx1">Related to, Japanese sentiment analysis...</h1><h2 class="css-ixasx1">日本の感情分析に関する、</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">A while ago, &quot;<a href="https://arxiv.org/abs/1905.09642" class="css-13b0teh">An Investigation of Transfer Learning-Based Sentiment Analysis in Japanese</a>&quot; was published on arXiv.org</h1><h2 class="css-ixasx1">少し前、ULMFiTと日本語自然言語処理に関する論文がarXiv.orgで公開されました。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">That paper was published by researchers of the company ExaWizards in Tokyo.</h1><h2 class="css-ixasx1">その論文は、東京のExaWizards株式会社の研究者によって発表されました。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">The ELMo, ULMFiT, and BERT language models were compared.</h1><h2 class="css-ixasx1">ELMo、ULMFiT、そしてBERTという言語モデルは比較されました。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">Specifically, the research was about pre-training a language model in an unsupervised manner...</h1><h2 class="css-ixasx1">具体的に、言語モデルは監督されないままで事前トレーニングして、</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">...and then fine-tuning it on a domain-specific dataset.</h1><h2 class="css-ixasx1">そして、ドメイン固有のデータセットを利用して、微調整する事です。</h2></div><div class="css-znkm8c"><div class="css-5r4te6"><div class="css-11ze7cv"><h1 class="css-ixasx1">Wikipedia is used for the pretrained model.</h1><h2 class="css-ixasx1">ウィキペディアは事前トレーニングモードに使用されます。</h2></div><div class="css-11ze7cv"><img src="/static/ulmfit-2a229e1a7915c58a4ff473e995edcd15.png" class="css-wnzno2"/></div></div></div><div class="css-znkm8c"><h1 class="css-ixasx1">The datasets used were the <a href="https://github.com/zhangxiangxiao/glyph" class="css-13b0teh">Japanese Rakuten product review binary and 5 class datasets</a>...</h1><h2 class="css-ixasx1">使用されたデータセットは、日本の楽天製品レビューデータセットで、</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">...as well as the <a href="https://github.com/dennybritz/sentiment-analysis" class="css-13b0teh">Japanese Yahoo movie review dataset</a>.</h1><h2 class="css-ixasx1">日本のYahoo映画レビューデータセットでした。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">The researchers said the Yahoo movie dataset &quot;better represents real life/practical situations&quot;.</h1><h2 class="css-ixasx1">Yahooの映画データセットが「実際の普段に解決するのが必要の問題」と言われました。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">It seems the ExaWizards code and models will be released sometime after the ACL 2019 Annual Meeting.</h1><h2 class="css-ixasx1">コードとモデルは、ACL 2019年次総会の後にリリースされる予定です。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">However, they have not been released yet.</h1><h2 class="css-ixasx1">しかし、まだリリースされていません。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">I thought I would try to make a classifier using the Yahoo movie dataset.</h1><h2 class="css-ixasx1">Yahooの映画データセットで分類子を作成しようと思いました。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">Fast.ai recommends the Wikitext-103 pretrained model for transfer learning.</h1><h2 class="css-ixasx1">Wikitext 103の事前学習済みモデルは、転移学習に勧められています。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">Unfortunately, Fast.ai provides Wikitext-103 for English only.</h1><h2 class="css-ixasx1">残念ながら、Fast.aiは英語のみのWikitext-103を提供しています。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">At this time, there seem to be no pretrained models for Wikitext-103 for Japanese.</h1><h2 class="css-ixasx1">現在、日本語版Wikitext-103の事前トレーニングモデルはないようです。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">There is a <a href="https://github.com/tsurushun/ulmfit-multilingual/tree/japanese" class="css-13b0teh">ulmfit-multilingual</a> repo for Japanese on github.</h1><h2 class="css-ixasx1">githubには、日本語用のulmfit-multilingual gitフォークがあります。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">It is for an older version of Fast.ai</h1><h2 class="css-ixasx1">Fast.aiの少し古いバージョン用です。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">However, I could update the repo, and train Wikitext-2.</h1><h2 class="css-ixasx1">しかし、レポジトリを更新し、Wikitext-2をトレーニング出来ました。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">Wikitext-2 is about 50 times smaller than Wikitext-103.</h1><h2 class="css-ixasx1">Wikitext-2は、Wikitext-103より約50倍小さいです。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">Unfortunately, I didn&#x27;t have enough RAM to train Wikitext-103.</h1><h2 class="css-ixasx1">残念ながら、Wikitext-103をトレーニングするためRAMが不十分でした。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">However, I thought Wikitext-2 would be enough to train a simple classifier.</h1><h2 class="css-ixasx1">しかし、単純な分類子を作成するにはWikitext-2で十分だと思いました。</h2></div><div class="css-znkm8c"><div class="css-5r4te6"><div class="css-11ze7cv"><h1 class="css-ixasx1">Step 1 complete.</h1><h2 class="css-ixasx1">ステップ1完成です。</h2></div><div class="css-11ze7cv"><img src="/static/ulmfit1-4262ccecd8cab5d7366cd8273880ae31.png" class="css-wnzno2"/></div></div></div><div class="css-znkm8c"><h1 class="css-ixasx1">Next, fine-tuning with the Yahoo movie dataset.</h1><h2 class="css-ixasx1">次はYahoo映画データセットを使用して微調整する事です。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">There are 91,196 reviews of 64 movies in the Yahoo movie dataset:</h1><h2 class="css-ixasx1">Yahooデータセットには64の映画の91,196件のレビューがあります</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">The next slide is the first review in the dataset.</h1><h2 class="css-ixasx1">次のスライドはデータセットの一番最初のレビューです。</h2></div><div class="css-znkm8c"><pre class="css-110mgx6" style="display:block;overflow-x:auto;padding:0.5em;background:#F0F0F0;color:#444"><code>movieName: おくりびと        

title: ♡ヒロスエのパンツ♡

text:   
を見れたのが意外な収穫でした♡\n\n邦画もたまには良いかな。

rating: <span style="color:#880000">3</span>
</code></pre></div><div class="css-znkm8c"><div class="css-5r4te6"><div class="css-11ze7cv"><h1 class="css-ixasx1">There are 5 ratings, and the classes are unbalanced.</h1><h2 class="css-ixasx1">5つの評価があり、クラスは不均衡です。</h2></div><div class="css-11ze7cv"><img src="/static/ratings-aaecf3bd91497f3d58d9887765cb6292.png" class="css-wnzno2"/></div></div></div><div class="css-znkm8c"><h1 class="css-ixasx1">I assumed good reviews would be longer than bad reviews.</h1><h2 class="css-ixasx1">良いレビューは悪いレビューよりも長いと思いました。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">In fact, the lengths were not so different.</h1><h2 class="css-ixasx1">実際、長さはそれほど違いはなかったです。</h2></div><div class="css-znkm8c"><h2 class="css-ixasx1">Review lengths レビューの長さ</h2><pre class="css-110mgx6" style="display:block;overflow-x:auto;padding:0.5em;background:#F0F0F0;color:#444"><code>        rating  mean    std     min  max            
        <span style="color:#880000">1</span>       <span style="color:#880000">245.2</span>   <span style="color:#880000">285.5</span>   <span style="color:#880000">1</span>    <span style="color:#880000">2104</span>
        <span style="color:#880000">2</span>       <span style="color:#880000">324.3</span>   <span style="color:#880000">317.7</span>   <span style="color:#880000">1</span>    <span style="color:#880000">2093</span>
        <span style="color:#880000">3</span>       <span style="color:#880000">344.4</span>   <span style="color:#880000">318.7</span>   <span style="color:#880000">1</span>    <span style="color:#880000">2067</span>
        <span style="color:#880000">4</span>       <span style="color:#880000">365.3</span>   <span style="color:#880000">334.6</span>   <span style="color:#880000">1</span>    <span style="color:#880000">2317</span>
        <span style="color:#880000">5</span>       <span style="color:#880000">343.9</span>   <span style="color:#880000">358.9</span>   <span style="color:#880000">0</span>    <span style="color:#880000">2242</span>
</code></pre></div><div class="css-znkm8c"><h1 class="css-ixasx1">The English example in the Fast.ai docs, uses 1000 reviews from the IMDB dataset.</h1><h2 class="css-ixasx1">Fast.aiドキュメントの英語の例は、IMDBデータセットの1000件のレビューを使用しています。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">Because I used Wikitext-2, I decided to use 10,000 reviews from the Yahoo dataset.</h1><h2 class="css-ixasx1">Wikitext-2を使用したため、Yahooデータセットから10,000件のレビューを使用する事にしました。</h2></div><div class="css-znkm8c"><pre class="css-110mgx6" style="display:block;overflow-x:auto;padding:0.5em;background:#F0F0F0;color:#444"><code>  learn = language_model_learner(
      data_lm, AWD_LSTM, 
      pretrained_fnames=(<span style="color:#880000">&#x27;qrnn_wt-2&#x27;</span>, <span style="color:#880000">&#x27;itos_wt-2&#x27;</span>), 
      drop_mult=<span style="color:#880000">0.5</span>
  )
  learn.fit_one_cycle(<span style="color:#880000">1</span>, <span style="color:#880000">1e-2</span>)

  epoch train_loss  valid_loss  accuracy  time
  <span style="color:#880000">0</span>     <span style="color:#880000">4.590764</span>    <span style="color:#880000">4.487607</span>    <span style="color:#880000">0.243777</span>  <span style="color:#880000">1</span>:<span style="color:#880000">20</span>:<span style="color:#880000">02</span>
</code></pre></div><div class="css-znkm8c"><pre class="css-110mgx6" style="display:block;overflow-x:auto;padding:0.5em;background:#F0F0F0;color:#444"><code>  learn.unfreeze()
  learn.fit_one_cycle(<span style="color:#880000">1</span>, <span style="color:#880000">1e-3</span>)

  epoch train_loss  valid_loss  accuracy  time
  <span style="color:#880000">0</span>     <span style="color:#880000">4.272850</span>    <span style="color:#880000">4.243399</span>    <span style="color:#880000">0.272256</span>  <span style="color:#880000">2</span>:<span style="color:#880000">06</span>:<span style="color:#880000">08</span>

  learn.save_encoder(<span style="color:#880000">&#x27;ft_enc&#x27;</span>)
</code></pre></div><div class="css-znkm8c"><div class="css-5r4te6"><div class="css-11ze7cv"><h1 class="css-ixasx1">Step 2 complete.</h1><h2 class="css-ixasx1">ステップ2完成です。</h2></div><div class="css-11ze7cv"><img src="/static/ulmfit2-cf9399381123da785a1f02582c26b3ee.png" class="css-wnzno2"/></div></div></div><div class="css-znkm8c"><h1 class="css-ixasx1">Next, training the classifier.</h1><h2 class="css-ixasx1">次に、分類器をトレーニングする事です。</h2></div><div class="css-znkm8c"><pre class="css-110mgx6" style="display:block;overflow-x:auto;padding:0.5em;background:#F0F0F0;color:#444"><code>classifier = text_classifier_learner(           
    data_clas, AWD_LSTM, 
    pretrained=False, 
    drop_mult=<span style="color:#880000">0.5</span>)
classifier.load_pretrained(
    wgts_fname=path/<span style="color:#880000">&#x27;models&#x27;</span>/<span style="color:#880000">&#x27;qrnn_wt-2.pth&#x27;</span>, 
    itos_fname=path/<span style="color:#880000">&#x27;models&#x27;</span>/<span style="color:#880000">&#x27;itos_wt-2.pkl&#x27;</span>, 
    strict=False)
classifier.load_encoder(<span style="color:#880000">&#x27;ft_enc&#x27;</span>)
</code></pre></div><div class="css-znkm8c"><pre class="css-110mgx6" style="display:block;overflow-x:auto;padding:0.5em;background:#F0F0F0;color:#444"><code> classifier.fit_one_cycle(<span style="color:#880000">1</span>, <span style="color:#880000">1e-2</span>)

 epoch train_loss  valid_loss  accuracy  time
 <span style="color:#880000">0</span>     <span style="color:#880000">0.577836</span>    <span style="color:#880000">0.508297</span>    <span style="color:#880000">0.756122</span>  <span style="color:#880000">1</span>:<span style="color:#880000">00</span>:<span style="color:#880000">52</span>
</code></pre></div><div class="css-znkm8c"><pre class="css-110mgx6" style="display:block;overflow-x:auto;padding:0.5em;background:#F0F0F0;color:#444"><code> classifier.freeze_to(<span style="color:#880000">-2</span>)
 classifier.fit_one_cycle(<span style="color:#880000">1</span>, slice(<span style="color:#880000">5e-3</span>/<span style="color:#880000">2.</span>, <span style="color:#880000">5e-3</span>))

 epoch train_loss  valid_loss  accuracy  time
 <span style="color:#880000">0</span>     <span style="color:#880000">0.429069</span>    <span style="color:#880000">0.360367</span>    <span style="color:#880000">0.837581</span>  <span style="color:#880000">1</span>:<span style="color:#880000">10</span>:<span style="color:#880000">35</span>
</code></pre></div><div class="css-znkm8c"><h1 class="css-ixasx1">Accuracy is almost the same as the 1000 IMDB sample in the Fast.ai docs.</h1><h2 class="css-ixasx1">精度は、Fast.aiドキュメントの1000 IMDBサンプルとほぼ同じです。</h2></div><div class="css-znkm8c"><div class="css-5r4te6"><div class="css-11ze7cv"><h1 class="css-ixasx1">Step 3 complete.</h1><h2 class="css-ixasx1">ステップ3完成です。</h2></div><div class="css-11ze7cv"><img src="/static/ulmfit3-7d12a1b0dee0e198aad886793fda9d37.png" class="css-wnzno2"/></div></div></div><div class="css-znkm8c"><h1 class="css-ixasx1">Success 成功</h1><pre class="css-110mgx6" style="display:block;overflow-x:auto;padding:0.5em;background:#F0F0F0;color:#444"><code> classifier.predict(<span style="color:#880000">&quot;すごく面白い映画です。&quot;</span>)          

 (Category positive, 
    tensor(<span style="color:#880000">1</span>), 
    tensor([<span style="color:#880000">3.5251e-05</span>, <span style="color:#880000">9.9996e-01</span>]))
</code></pre></div><div class="css-znkm8c"><h1 class="css-ixasx1">To improve, I would like to try using Japanese Wikitext-103...</h1><h2 class="css-ixasx1">改善するためには、日本語Wikitext-103を使用したいと思います、</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">...and, improve tokenization.</h1><h2 class="css-ixasx1">そして、トークン化を改善したいです。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">By default, Fast.ai uses <a href="https://spacy.io/" class="css-13b0teh">spacy</a> for tokenization.</h1><h2 class="css-ixasx1">デフォルトでは、Fast.aiはトークン化にspacyを使用します。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">However, the github repo has a TODO: &quot;<a href="https://github.com/fastai/fastai/blob/4a7c6b6a21152de4af86cee1d48e844f509f6625/courses/dl2/imdb_scripts/create_toks.py#L48" class="css-13b0teh">handle tokenization of Chinese, Japanese, Korean</a>&quot;.</h1><h2 class="css-ixasx1">しかし、githubリポジトリにはTODOがあります：「中国語、日本語、韓国語のトークン化を処理する」</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">Tokenization of Japanese is not officially supported.</h1><h2 class="css-ixasx1">日本語のトークン化は公式にはサポートされていません。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">The ulmfit-multilingual repo uses SentencePiece, so I used that.</h1><h2 class="css-ixasx1">ulmfit-multilingualリポジトリはSentencePieceを使用するので、それを使用しました。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">But, I was not satisfied with the tokenization.</h1><h2 class="css-ixasx1">しかし、トークン化には満足していませんでした。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">I tried other tokenizers, including MeCab, Janome, Rakuten MA, SudachiPy, and Nagisa.</h1><h2 class="css-ixasx1">他のトークナイザーを試しました。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">The Exawizards researchers used a MeCab tokenizer.</h1><h2 class="css-ixasx1">Exawizardsの研究者はMeCabトークナイザーを使用しました。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">When Exawizards release their code I would like to look at their tokenization method.</h1><h2 class="css-ixasx1">Exawizardsがコードをリリースする時、トークン化の方法を見たいと思います。</h2></div><div class="css-znkm8c"><h1 class="css-ixasx1">That’s all. Thanks for listening.</h1><h2 class="css-ixasx1">以上です。ご清聴ありがとうございます。</h2></div></div></div></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="//print";window.webpackCompilationHash="b6d191fb2175e7246e60";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"app":["/app-084c1664e71b26798f10.js"],"component---gatsby-theme-mdx-deck-src-templates-deck-js":[]};/*]]>*/</script><script src="/webpack-runtime-b22280da432b197f4c69.js" async=""></script><script src="/app-084c1664e71b26798f10.js" async=""></script><script src="/2-f8806a5584b02803e598.js" async=""></script></body></html>